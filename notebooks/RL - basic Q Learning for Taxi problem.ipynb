{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In Reinforcement Learning(RL), an agent(or algorithm) learns by the method of trial and error.\n",
    "One of the hard parts of Reinforcement Learning is to model the environment and how agent interacts with it. Once we have a model for this, we can start generating data for learning as the agent interacts with the environment and starts gathering the rewards. The goal of learning is to maximize the rewards in the long term.\n",
    "\n",
    "OpenAI gym library is basically the UCI for Reinforcement learning problems.\n",
    "https://gym.openai.com/docs/\n",
    "\n",
    "It provides simulation models for a number of environments where we can apply RL.\n",
    "\n",
    "We will consider the taxi problem for this demo  \n",
    "https://gym.openai.com/envs/Taxi-v3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | :\u001b[43m \u001b[0m:\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Taxi-v3')\n",
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The above visual shows an area which has been divided into 5x5 grid\n",
    "* There is a self driving taxi (indicated by yellow mark when empty and green mark when passenger has occupied it).\n",
    "* The goal for self driving taxi is to pick up the passenger from one of the 4 locations and drop off to another location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The Taxi Problem\n",
      "    from \"Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition\"\n",
      "    by Tom Dietterich\n",
      "\n",
      "    Description:\n",
      "    There are four designated locations in the grid world indicated by R(ed), G(reen), Y(ellow), and B(lue). When the episode starts, the taxi starts off at a random square and the passenger is at a random location. The taxi drives to the passenger's location, picks up the passenger, drives to the passenger's destination (another one of the four specified locations), and then drops off the passenger. Once the passenger is dropped off, the episode ends.\n",
      "\n",
      "    Observations: \n",
      "    There are 500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger (including the case when the passenger is in the taxi), and 4 destination locations. \n",
      "    \n",
      "    Passenger locations:\n",
      "    - 0: R(ed)\n",
      "    - 1: G(reen)\n",
      "    - 2: Y(ellow)\n",
      "    - 3: B(lue)\n",
      "    - 4: in taxi\n",
      "    \n",
      "    Destinations:\n",
      "    - 0: R(ed)\n",
      "    - 1: G(reen)\n",
      "    - 2: Y(ellow)\n",
      "    - 3: B(lue)\n",
      "        \n",
      "    Actions:\n",
      "    There are 6 discrete deterministic actions:\n",
      "    - 0: move south\n",
      "    - 1: move north\n",
      "    - 2: move east \n",
      "    - 3: move west \n",
      "    - 4: pickup passenger\n",
      "    - 5: dropoff passenger\n",
      "    \n",
      "    Rewards: \n",
      "    There is a reward of -1 for each action and an additional reward of +20 for delivering the passenger. There is a reward of -10 for executing actions \"pickup\" and \"dropoff\" illegally.\n",
      "    \n",
      "\n",
      "    Rendering:\n",
      "    - blue: passenger\n",
      "    - magenta: destination\n",
      "    - yellow: empty taxi\n",
      "    - green: full taxi\n",
      "    - other letters (R, G, Y and B): locations for passengers and destinations\n",
      "    \n",
      "\n",
      "    state space is represented by:\n",
      "        (taxi_row, taxi_col, passenger_location, destination)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from gym.envs.toy_text.taxi import TaxiEnv\n",
    "print(TaxiEnv.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do we solve this problem using Reinforcement Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set the terminology right  \n",
    "\n",
    "Environment: 5x5 space in which the taxi ferries the passenger from pickup to drop location (universe in which the agent performs action and learns)  \n",
    "Agent: Taxi (learner)  \n",
    "Action: Taxi moves 1 grid east/west/north/south or picks/drops passenger  \n",
    "State: One of the 500 possible states of the environment with a specific position of taxi and passenger  \n",
    "Reward: -1 for each action, +20 for correct drop off, -10 for incorrect drop-off \n",
    "\n",
    "RL - Solve the problem of maximizing the reward in the long term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use the Q-learning algorithm to solve this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(500)\n",
      "Discrete(6)\n"
     ]
    }
   ],
   "source": [
    "# There are 500 possible states and 6 possible actions\n",
    "print(env.env.observation_space)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets drive step by step to better understand the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m:\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B(Blue) is the passenger location\n",
    "# R(magenta) is the destination\n",
    "# Taxi is indicated by yellow\n",
    "env.env.s = 492\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m: |\n",
      "+---------+\n",
      "  (West)\n"
     ]
    }
   ],
   "source": [
    "#Move West\n",
    "env.step(3)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[42mB\u001b[0m: |\n",
      "+---------+\n",
      "  (Pickup)\n"
     ]
    }
   ],
   "source": [
    "#pick up the passenger\n",
    "env.step(4)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start towards destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : |\u001b[42m_\u001b[0m: |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n"
     ]
    }
   ],
   "source": [
    "env.step(1)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35m\u001b[42mR\u001b[0m\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (North)\n"
     ]
    }
   ],
   "source": [
    "# Fast forward to destination\n",
    "\n",
    "env.step(1)\n",
    "env.step(3)\n",
    "env.step(3)\n",
    "env.step(3)\n",
    "env.step(1)\n",
    "env.step(1)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n"
     ]
    }
   ],
   "source": [
    "# Drop off (Taxi becomes yellow)\n",
    "env.step(5)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets try to solve the problem by brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13136 -51212\n"
     ]
    }
   ],
   "source": [
    "reward = 0\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "env.reset()\n",
    "while reward!=20:\n",
    "    action = env.env.action_space.sample() # Determine a random action\n",
    "    _, reward, _, _ = env.step(action) # Perform the action\n",
    "    total_reward += reward # Accumulate reward\n",
    "    steps+=1 # Count the steps\n",
    "print(steps, total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve the problem using q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q-learning is similar to Dynamic Programming. \n",
    "(Both are based on Bellman's equation. In Dynamic programming, the idea is to simply store the results of subproblems, so that we do not have to re-compute them when needed later. E.g. Finding factorial for a number)\n",
    "\n",
    "In Q-learning, we learn the Q-table, which is a matrix of expected rewards for state transition based on a certain action.\n",
    "Each row represents state of the model  \n",
    "Each columns represents an action  \n",
    "Each cell represents expected reward when a certain action is performed  \n",
    "\n",
    "![Image](https://wikimedia.org/api/rest_v1/media/math/render/svg/678cb558a9d59c33ef4810c9618baf34a9577686)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>South</th>\n",
       "      <th>North</th>\n",
       "      <th>East</th>\n",
       "      <th>West</th>\n",
       "      <th>Pickup</th>\n",
       "      <th>Dropoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     South  North  East  West  Pickup  Dropoff\n",
       "0      0.0    0.0   0.0   0.0     0.0      0.0\n",
       "1      0.0    0.0   0.0   0.0     0.0      0.0\n",
       "2      0.0    0.0   0.0   0.0     0.0      0.0\n",
       "3      0.0    0.0   0.0   0.0     0.0      0.0\n",
       "4      0.0    0.0   0.0   0.0     0.0      0.0\n",
       "..     ...    ...   ...   ...     ...      ...\n",
       "495    0.0    0.0   0.0   0.0     0.0      0.0\n",
       "496    0.0    0.0   0.0   0.0     0.0      0.0\n",
       "497    0.0    0.0   0.0   0.0     0.0      0.0\n",
       "498    0.0    0.0   0.0   0.0     0.0      0.0\n",
       "499    0.0    0.0   0.0   0.0     0.0      0.0\n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Q table with zeros\n",
    "Q = np.zeros((env.env.observation_space.n, env.action_space.n))\n",
    "print(Q.shape)\n",
    "actions = \"South North East West Pickup Dropoff\".split()\n",
    "pd.DataFrame(Q, columns = actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-524\n",
      "-88\n",
      "-76\n",
      "14\n",
      "5\n",
      "1\n",
      "5\n",
      "10\n",
      "6\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.7 #learning rate\n",
    "gamma = 0.8 #discount factor\n",
    "episodes = 1000\n",
    "Q = np.zeros((env.env.observation_space.n, env.action_space.n))\n",
    "\n",
    "learning = {}\n",
    "for episode in range(episodes):\n",
    "    cur_state = env.reset()\n",
    "    reward = 0\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        #action = env.env.action_space.sample()\n",
    "        action = np.argmax(Q[cur_state])\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        Q[cur_state][action] += alpha*(reward + gamma*(np.max(Q[next_state]) - Q[cur_state][action]))\n",
    "        cur_state = next_state\n",
    "    learning[episode] = total_reward\n",
    "    if episode % 100 == 0:\n",
    "        print(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a20736950>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Learning curve\n",
    "sns.lineplot(x = 0, y = 1, data = pd.DataFrame(learning.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the learning is completed by ~ 400 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>South</th>\n",
       "      <th>North</th>\n",
       "      <th>East</th>\n",
       "      <th>West</th>\n",
       "      <th>Pickup</th>\n",
       "      <th>Dropoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-7.552651</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-6.903858</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>13.75</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-3.511544</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-3.447908</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>18.75</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-6.206110</td>\n",
       "      <td>-6.300000</td>\n",
       "      <td>-6.817890</td>\n",
       "      <td>-6.300000</td>\n",
       "      <td>15.00</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-12.804649</td>\n",
       "      <td>-13.300000</td>\n",
       "      <td>-13.357784</td>\n",
       "      <td>-13.300000</td>\n",
       "      <td>-14.00</td>\n",
       "      <td>-14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>-6.300000</td>\n",
       "      <td>-6.224872</td>\n",
       "      <td>-6.300000</td>\n",
       "      <td>-6.168029</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-3.152936</td>\n",
       "      <td>-3.500000</td>\n",
       "      <td>-3.137851</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>-5.600000</td>\n",
       "      <td>-1.417172</td>\n",
       "      <td>-5.600000</td>\n",
       "      <td>-6.059126</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>-1.400000</td>\n",
       "      <td>6.832000</td>\n",
       "      <td>-7.00</td>\n",
       "      <td>-7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         South      North       East       West  Pickup  Dropoff\n",
       "0     0.000000   0.000000   0.000000   0.000000    0.00      0.0\n",
       "1    -7.552651  -7.000000  -6.903858  -7.000000   13.75     -7.0\n",
       "2    -3.511544  -3.500000  -3.447908  -3.500000   18.75     -7.0\n",
       "3    -6.206110  -6.300000  -6.817890  -6.300000   15.00     -7.0\n",
       "4   -12.804649 -13.300000 -13.357784 -13.300000  -14.00    -14.0\n",
       "..         ...        ...        ...        ...     ...      ...\n",
       "495   0.000000   0.000000   0.000000   0.000000    0.00      0.0\n",
       "496  -6.300000  -6.224872  -6.300000  -6.168029   -7.00     -7.0\n",
       "497  -3.500000  -3.152936  -3.500000  -3.137851   -7.00     -7.0\n",
       "498  -5.600000  -1.417172  -5.600000  -6.059126   -7.00     -7.0\n",
       "499  -1.400000  -1.400000  -1.400000   6.832000   -7.00     -7.0\n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q table after training\n",
    "pd.DataFrame(Q, columns = actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n",
      "+---------+\n",
      "|R: | : :\u001b[42mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Pickup)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : :\u001b[42m_\u001b[0m|\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : :\u001b[42m_\u001b[0m|\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[42m_\u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : :\u001b[42m_\u001b[0m: : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| :\u001b[42m_\u001b[0m: : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "|\u001b[42m_\u001b[0m: : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (West)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[42m_\u001b[0m| : | : |\n",
      "|\u001b[35mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35m\u001b[42mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "  (Dropoff)\n",
      "10 11\n"
     ]
    }
   ],
   "source": [
    "# Lets traverse the path based on q-learning solution\n",
    "reward = 0\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "s = env.reset()\n",
    "env.render()\n",
    "done = False\n",
    "while not done:\n",
    "    action = np.argmax(Q[s])\n",
    "    s, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    total_reward += reward\n",
    "    steps+=1\n",
    "print(steps, total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other algorithms to explore\n",
    "\n",
    "### SARSA: Epsilon-greedy Q-learning\n",
    "\n",
    "### DQN: Deep Q-Network\n",
    "* Q table is replaced by a neural network which represents a Q function\n",
    "* Can be used to predict action for unseen states unlike Q table \n",
    "\n",
    "### DDPG (Deep Deterministic Policy Gradient):\n",
    "*  Used for very large action spaces\n",
    "\n",
    "## Taxonomy of RL Algorithms:  \n",
    "* Model Based vs. Model Free (You do not need to know all the states of environment upfront)  \n",
    "https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading\n",
    "https://spinningup.openai.com/en/latest/index.html\n",
    "http://incompleteideas.net/book/bookdraft2017nov5.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
